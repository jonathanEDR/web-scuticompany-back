/**
 * OpenAI Service MEJORADO - Gesti√≥n inteligente de contexto y tokens
 * Sistema avanzado de optimizaci√≥n y personalizaci√≥n para agentes AI
 */

import axios from 'axios';
import contextManager from '../context/AgentContextManager.js';
import personalitySystem from '../context/AgentPersonalitySystem.js';
import dynamicPromptSystem from '../context/DynamicPromptSystem.js';
import intelligentMemorySystem from '../memory/IntelligentMemorySystem.js';
import logger from '../../utils/logger.js';

class OpenAIService {
  constructor() {
    // NO asignar apiKey aqu√≠ - hacerlo din√°micamente en getApiKey()
    this.baseURL = 'https://api.openai.com/v1';
    this.model = 'gpt-4o'; // Modelo m√°s reciente
    
    // Configuraci√≥n inteligente por defecto
    this.defaultConfig = {
      temperature: 0.7,
      max_tokens: 2000,
      top_p: 1,
      frequency_penalty: 0.1,
      presence_penalty: 0.1
    };

    // Sistema de cach√© inteligente
    this.cache = new Map();
    this.cacheTimeout = 10 * 60 * 1000; // 10 minutos
    this.cachePriority = new Map(); // Prioridad de cach√©
    
    // M√©tricas y optimizaci√≥n
    this.metrics = {
      totalRequests: 0,
      cachedResponses: 0,
      tokensSaved: 0,
      averageResponseTime: 0,
      errorRate: 0,
      costOptimization: 0
    };

    // Configuraci√≥n de l√≠mites de tokens
    this.tokenLimits = {
      'gpt-4o': 128000,
      'gpt-4-turbo': 128000,
      'gpt-4': 8192,
      'gpt-3.5-turbo': 16384
    };

    // Sistema de fallback
    this.fallbackStrategies = new Map();
    this.initializeFallbackStrategies();

    logger.success('ü§ñ Enhanced OpenAI Service initialized with intelligent context management');
  }

  /**
   * Obtener API key din√°micamente (permite cambios en runtime)
   */
  getApiKey() {
    return process.env.OPENAI_API_KEY;
  }

  /**
   * Verificar si OpenAI est√° disponible
   */
  isAvailable() {
    const apiKey = this.getApiKey();
    return !!apiKey;
  }

  /**
   * Generar respuesta inteligente con contexto personalizado
   */
  async generateIntelligentResponse(sessionId, agentName, userMessage, taskContext = {}) {
    const startTime = Date.now();
    this.metrics.totalRequests++;

    try {
      if (!this.isAvailable()) {
        return await this.handleFallback(agentName, userMessage, taskContext);
      }

      // Obtener contexto completo del agente
      const contextData = await contextManager.generateOptimizedContext(sessionId, agentName, taskContext);
      const agentProfile = await personalitySystem.getAgentProfile(agentName);
      
      // Construir mensajes optimizados
      const messages = await this.buildOptimizedMessages(
        contextData, 
        agentProfile, 
        userMessage, 
        taskContext
      );

      // Verificar cach√© inteligente
      const cacheKey = this.generateSmartCacheKey(messages, agentName);
      const cached = this.getFromSmartCache(cacheKey);
      if (cached) {
        logger.info('üéØ Using intelligent cached response');
        this.metrics.cachedResponses++;
        return cached;
      }

      // Configurar par√°metros seg√∫n perfil del agente
      const requestConfig = this.buildRequestConfig(agentProfile, taskContext);
      requestConfig.messages = messages;

      // Validar l√≠mite de tokens
      const tokenCount = this.estimateTokenCount(messages);
      if (tokenCount > this.getTokenLimit(requestConfig.model) * 0.9) {
        logger.warn(`‚ö†Ô∏è  Token count (${tokenCount}) approaching limit, optimizing...`);
        requestConfig.messages = await this.optimizeMessagesForTokens(messages, requestConfig.model);
      }

      logger.info(`ü§ñ Calling OpenAI API for ${agentName} (${tokenCount} tokens)`);
      
      if (!this.isAvailable()) {
        throw new Error('OpenAI API key no disponible');
      }
      
      const response = await this.callOpenAI(requestConfig);
      
      // Procesar y personalizar respuesta
      const processedResponse = await this.processIntelligentResponse(
        response, 
        agentProfile, 
        contextData, 
        taskContext
      );

      // Actualizar contexto y m√©tricas
      await this.updateContextAndMetrics(sessionId, agentName, userMessage, processedResponse, startTime);

      // Guardar en cach√© inteligente
      this.saveToSmartCache(cacheKey, processedResponse, agentProfile);

      return processedResponse;

    } catch (error) {
      this.metrics.errorRate = (this.metrics.errorRate + 1) / this.metrics.totalRequests;
      logger.error('‚ùå Intelligent response generation failed:', error.message);
      
      // Intentar estrategia de fallback
      return await this.handleFallback(agentName, userMessage, taskContext, error);
    }
  }

  /**
   * Construir mensajes avanzados con todos los sistemas integrados
   */
  async buildAdvancedOptimizedMessages(userMessage, dynamicPrompt, contextData, agentProfile, intelligentContext, options = {}) {
    const messages = [];

    try {
      // 1. Prompt din√°mico del sistema con personalidad e inteligencia
      let systemContent = dynamicPrompt.content;
      
      // Aplicar adaptaciones del usuario si est√°n disponibles
      if (intelligentContext.user.adaptations) {
        systemContent = this.applyUserAdaptations(systemContent, intelligentContext.user.adaptations);
      }
      
      messages.push({
        role: 'system',
        content: systemContent
      });

      // 2. Contexto de conversaci√≥n optimizado
      if (contextData.conversationHistory && contextData.conversationHistory.length > 0) {
        const optimizedHistory = await this.optimizeConversationHistory(
          contextData.conversationHistory,
          intelligentContext.user.preferences
        );
        
        messages.push(...optimizedHistory);
      }

      // 3. Contexto adicional si est√° disponible
      if (contextData.additionalContext && Object.keys(contextData.additionalContext).length > 0) {
        const contextString = this.formatAdditionalContext(contextData.additionalContext);
        messages.push({
          role: 'system',
          content: `CONTEXTO ADICIONAL:\n${contextString}`
        });
      }

      // 4. Mensaje del usuario con mejoras inteligentes
      const enhancedUserMessage = this.enhanceUserMessage(userMessage, intelligentContext, options);
      messages.push({
        role: 'user',
        content: enhancedUserMessage
      });

      return messages;
      
    } catch (error) {
      logger.error('‚ùå Error building advanced optimized messages:', error);
      return this.buildFallbackMessages(userMessage, agentProfile);
    }
  }

  /**
   * Aplicar adaptaciones del usuario al contenido
   */
  applyUserAdaptations(content, adaptations) {
    let adaptedContent = content;
    
    // Adaptaciones de comunicaci√≥n
    adaptations.communication?.forEach(adaptation => {
      switch (adaptation) {
        case 'use_formal_language':
          adaptedContent += '\n\n‚ö†Ô∏è  IMPORTANTE: Utiliza un lenguaje formal y profesional en toda la respuesta.';
          break;
        case 'use_casual_tone':
          adaptedContent += '\n\nüí¨ NOTA: Mant√©n un tono casual y amigable en la comunicaci√≥n.';
          break;
        case 'include_technical_details':
          adaptedContent += '\n\nüîß ENFOQUE: Incluye detalles t√©cnicos espec√≠ficos y explicaciones profundas.';
          break;
      }
    });

    // Adaptaciones de contenido
    adaptations.content?.forEach(adaptation => {
      switch (adaptation) {
        case 'include_practical_examples':
          adaptedContent += '\n\nüìù REQUERIMIENTO: Incluye ejemplos pr√°cticos y casos de uso reales.';
          break;
        case 'include_performance_metrics':
          adaptedContent += '\n\nüìä M√âTRICAS: Proporciona m√©tricas de rendimiento y KPIs relevantes.';
          break;
        case 'prioritize_quick_implementations':
          adaptedContent += '\n\n‚ö° PRIORIDAD: Enf√≥cate en soluciones r√°pidas de implementar (quick wins).';
          break;
      }
    });

    // Adaptaciones de estructura
    adaptations.structure?.forEach(adaptation => {
      switch (adaptation) {
        case 'use_concise_format':
          adaptedContent += '\n\nüìã FORMATO: Mant√©n respuestas concisas y directas al punto.';
          break;
        case 'use_detailed_format':
          adaptedContent += '\n\nüìö FORMATO: Proporciona an√°lisis detallado y exhaustivo.';
          break;
      }
    });

    return adaptedContent;
  }

  /**
   * Optimizar historial de conversaci√≥n basado en preferencias
   */
  async optimizeConversationHistory(history, userPreferences) {
    const optimized = [];
    
    // Determinar cu√°ntos mensajes incluir basado en preferencias
    const maxMessages = this.getMaxHistoryMessages(userPreferences);
    const recentHistory = history.slice(-maxMessages);
    
    for (const interaction of recentHistory) {
      // Agregar mensaje del usuario
      if (interaction.userMessage) {
        optimized.push({
          role: 'user',
          content: interaction.userMessage
        });
      }
      
      // Agregar respuesta del asistente (resumida si es necesario)
      if (interaction.response) {
        let responseContent = interaction.response;
        
        // Resumir si el usuario prefiere respuestas breves
        if (userPreferences?.communication?.detail_level === 'brief' && responseContent.length > 500) {
          responseContent = this.summarizeResponse(responseContent);
        }
        
        optimized.push({
          role: 'assistant',
          content: responseContent
        });
      }
    }
    
    return optimized;
  }

  /**
   * Mejorar mensaje del usuario con contexto inteligente
   */
  enhanceUserMessage(userMessage, intelligentContext, options) {
    let enhanced = userMessage;
    
    // Agregar contexto de tarea si est√° disponible
    if (options.taskType) {
      enhanced = `[TIPO DE TAREA: ${options.taskType}]\n\n${enhanced}`;
    }
    
    // Agregar informaci√≥n de contenido si est√° disponible
    if (options.contentData) {
      const contentInfo = `[CONTENIDO A ANALIZAR: "${options.contentData.title}" - Categor√≠a: ${options.contentData.category?.name || 'N/A'}]\n\n`;
      enhanced = contentInfo + enhanced;
    }
    
    // Agregar preferencias de an√°lisis si est√°n disponibles
    if (intelligentContext.optimization.recommended_approach) {
      const approach = intelligentContext.optimization.recommended_approach;
      enhanced += `\n\n[ENFOQUE RECOMENDADO: ${approach.description}]`;
    }
    
    return enhanced;
  }

  /**
   * Procesar respuesta inteligente con adaptaciones
   */
  async processIntelligentResponse(response, agentProfile, intelligentContext, options) {
    try {
      let content = response.choices[0]?.message?.content || '';
      
      // Aplicar adaptaciones de personalidad
      if (agentProfile?.personality) {
        content = personalitySystem.adaptResponseStyle(content, agentProfile.personality);
      }
      
      // Aplicar adaptaciones basadas en preferencias del usuario
      content = this.applyResponseAdaptations(content, intelligentContext.user.preferences);
      
      // Agregar elementos adicionales seg√∫n preferencias
      content = this.enhanceResponseWithPreferences(content, intelligentContext.user.preferences);
      
      // Calcular satisfacci√≥n predicha
      const predictedSatisfaction = this.calculatePredictedSatisfaction(
        content, 
        intelligentContext.optimization.predicted_success_rate
      );
      
      return {
        success: true,
        content: content,
        predictedSatisfaction: predictedSatisfaction,
        model: response.model,
        usage: response.usage,
        metadata: {
          intelligence_applied: true,
          adaptations_count: this.countAppliedAdaptations(intelligentContext.user.adaptations)
        }
      };
      
    } catch (error) {
      logger.error('‚ùå Error processing intelligent response:', error);
      return this.processStandardResponse(response, agentProfile);
    }
  }

  /**
   * Construir mensajes optimizados para el contexto (m√©todo original mejorado)
   */
  async buildOptimizedMessages(contextData, agentProfile, userMessage, taskContext) {
    const messages = [];

    // 1. Sistema personalizado con contexto
    const systemPrompt = personalitySystem.generatePersonalizedPrompt(agentProfile, {
      ...contextData.additionalContext,
      currentTask: taskContext,
      sessionContext: contextData.conversationId
    });

    messages.push({
      role: 'system',
      content: systemPrompt
    });

    // 2. Contexto de conversaci√≥n (mensajes relevantes)
    if (contextData.messages && contextData.messages.length > 0) {
      const relevantMessages = contextData.messages
        .slice(-agentProfile.technicalConfig?.contextWindow || 10)
        .map(msg => ({
          role: msg.role,
          content: msg.content
        }));
      
      messages.push(...relevantMessages);
    }

    // 3. Contexto adicional relevante
    if (contextData.additionalContext) {
      const contextSummary = this.formatAdditionalContext(contextData.additionalContext);
      if (contextSummary) {
        messages.push({
          role: 'system',
          content: `CONTEXTO ADICIONAL:\n${contextSummary}`
        });
      }
    }

    // 4. Mensaje actual del usuario
    messages.push({
      role: 'user',
      content: userMessage
    });

    return messages;
  }

  /**
   * Configurar par√°metros seg√∫n perfil del agente
   */
  buildRequestConfig(agentProfile, taskContext) {
    const config = { ...this.defaultConfig };
    
    if (agentProfile?.technicalConfig) {
      const tech = agentProfile.technicalConfig;
      
      config.temperature = tech.temperature || config.temperature;
      config.max_tokens = Math.min(tech.maxTokens || 2000, 4000);
      
      // Ajustes seg√∫n tipo de tarea
      if (taskContext.requiresPrecision) {
        config.temperature = Math.min(config.temperature, 0.3);
      } else if (taskContext.requiresCreativity) {
        config.temperature = Math.max(config.temperature, 0.8);
      }
    }

    // Modelo seg√∫n complejidad de la tarea
    config.model = this.selectOptimalModel(taskContext, agentProfile);
    
    return config;
  }

  /**
   * Seleccionar modelo √≥ptimo seg√∫n tarea y perfil
   */
  selectOptimalModel(taskContext, agentProfile) {
    const complexity = taskContext.complexity || 'medium';
    const requiresLatestModel = taskContext.requiresLatestFeatures || false;
    
    if (requiresLatestModel || complexity === 'high') {
      return 'gpt-4o';
    } else if (complexity === 'medium') {
      return 'gpt-4-turbo';
    } else {
      return 'gpt-3.5-turbo';
    }
  }

  /**
   * Llamada optimizada a OpenAI con reintentos
   */
  async callOpenAI(requestConfig, retries = 3) {
    const apiKey = this.getApiKey();
    if (!apiKey) {
      throw new Error('‚ùå OpenAI API key no configurada. Verifica tu archivo .env');
    }

    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        logger.info(`üîó Calling OpenAI API (attempt ${attempt}/${retries})...`);
        logger.info(`üìã Request config: model=${requestConfig.model}, max_tokens=${requestConfig.max_tokens}`);
        
        const response = await axios.post(
          `${this.baseURL}/chat/completions`,
          requestConfig,
          {
            headers: {
              'Authorization': `Bearer ${apiKey}`,
              'Content-Type': 'application/json'
            },
            timeout: 45000 // 45 segundos para requests complejos
          }
        );

        return response.data;

      } catch (error) {
        logger.error(`‚ùå API Error (attempt ${attempt}):`, {
          status: error.response?.status,
          statusText: error.response?.statusText,
          error: error.response?.data?.error,
          message: error.message
        });

        if (attempt === retries) {
          throw error;
        }
        
        // Esperar antes del reintento
        await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        
        // Reducir tokens si es error de l√≠mite
        if (error.response?.status === 400 && error.response?.data?.error?.code === 'context_length_exceeded') {
          requestConfig.messages = await this.optimizeMessagesForTokens(requestConfig.messages, requestConfig.model);
          logger.warn(`‚ö†Ô∏è  Reduced token count for retry ${attempt}`);
        }
      }
    }
  }

  /**
   * Procesar respuesta con personalizaci√≥n del agente
   */
  async processIntelligentResponse(response, agentProfile, contextData, taskContext) {
    let content = response.choices[0].message.content;
    
    // Aplicar estilo de personalidad
    if (agentProfile) {
      content = personalitySystem.adaptResponseStyle(content, agentProfile);
    }

    // Estructurar respuesta seg√∫n configuraci√≥n
    const structuredResponse = this.structureResponse(content, agentProfile, taskContext);

    return {
      content: structuredResponse,
      rawContent: response.choices[0].message.content,
      usage: response.usage,
      model: response.model,
      agentName: agentProfile?.agentName || 'unknown',
      personalityApplied: !!agentProfile,
      contextUsed: !!contextData.conversationId,
      processingTime: Date.now() - (contextData.startTime || Date.now()),
      timestamp: new Date()
    };
  }

  /**
   * Estructurar respuesta seg√∫n configuraci√≥n del agente
   */
  structureResponse(content, agentProfile, taskContext) {
    if (!agentProfile?.responseConfig) {
      return content;
    }

    const config = agentProfile.responseConfig;
    let structured = content;

    // Agregar estructura si es necesario
    if (config.includeSteps && !structured.includes('PASOS:') && !structured.includes('1.')) {
      // Intentar extraer pasos del contenido
      if (taskContext.type === 'optimize' || taskContext.type === 'analyze') {
        structured += '\n\nüìã PASOS RECOMENDADOS:\n1. Revisar las sugerencias anteriores\n2. Implementar cambios prioritarios\n3. Medir resultados';
      }
    }

    if (config.includeMetrics && taskContext.type === 'analyze') {
      structured += '\n\nüìä M√âTRICAS CLAVE:\n- Rendimiento actual evaluado\n- Oportunidades de mejora identificadas';
    }

    if (config.includeRecommendations && !structured.toLowerCase().includes('recomend')) {
      structured += '\n\nüí° RECOMENDACI√ìN:\nRevisa los puntos destacados y prioriza las acciones de mayor impacto.';
    }

    return structured;
  }

  /**
   * Generar respuesta de chat tradicional (retrocompatibilidad)
   */
  async generateChatResponse(messages, config = {}) {
    try {
      if (!this.isAvailable()) {
        throw new Error('OpenAI API key not configured');
      }

      // Verificar cach√© simple
      const cacheKey = this.generateCacheKey(messages);
      const cached = this.getFromCache(cacheKey);
      if (cached) {
        logger.info('üéØ Using cached OpenAI response');
        return cached;
      }

      const requestConfig = {
        ...this.defaultConfig,
        ...config,
        model: config.model || this.model,
        messages: this.formatMessages(messages)
      };

      logger.info('ü§ñ Calling OpenAI API (traditional)...');
      const response = await this.callOpenAI(requestConfig);

      const result = {
        content: response.choices[0].message.content,
        usage: response.usage,
        model: response.model,
        timestamp: new Date()
      };

      // Guardar en cach√©
      this.saveToCache(cacheKey, result);

      logger.success('‚úÖ OpenAI response received');
      return result;

    } catch (error) {
      logger.error('‚ùå OpenAI API error:', error.response?.data || error.message);
      throw new Error(`OpenAI API error: ${error.response?.data?.error?.message || error.message}`);
    }
  }

  /**
   * Generar contenido a partir de un prompt de texto simple
   * Compatible con BlogAgent.chat() y otros m√©todos
   */
  async generateCompletion(prompt, config = {}) {
    try {
      if (!this.isAvailable()) {
        throw new Error('OpenAI API key not configured');
      }

      const finalConfig = {
        temperature: config.temperature !== undefined ? config.temperature : 0.7,
        max_tokens: config.maxTokens || config.max_tokens || 500,
        model: config.model || this.model,
        top_p: 1,
        frequency_penalty: 0.1,
        presence_penalty: 0.1,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ]
      };

      logger.info('ü§ñ Generating completion from prompt...');
      const response = await this.callOpenAI(finalConfig);

      const content = response.choices[0].message.content;
      
      logger.success('‚úÖ Completion generated');
      return content;

    } catch (error) {
      logger.error('‚ùå Error generating completion:', error.response?.data || error.message);
      throw error;
    }
  }

  /**
   * Analizar texto y extraer intenciones
   */
  async analyzeIntent(text, context = {}) {
    try {
      const messages = [
        {
          role: 'system',
          content: `Eres un asistente especializado en an√°lisis de intenciones para un sistema de gesti√≥n de blog.
          
Tu trabajo es analizar comandos en lenguaje natural y determinar:
1. La acci√≥n que se desea realizar
2. El m√≥dulo o √°rea afectada
3. Los par√°metros espec√≠ficos
4. El nivel de prioridad

Contexto del sistema:
- Gesti√≥n de blog y contenido
- Optimizaci√≥n SEO
- An√°lisis de m√©tricas
- Moderaci√≥n de comentarios
- Gesti√≥n de usuarios

Responde SIEMPRE en formato JSON con esta estructura:
{
  "intent": "acci√≥n_principal",
  "module": "m√≥dulo_afectado",
  "action": "acci√≥n_espec√≠fica",
  "parameters": {...},
  "priority": "high|medium|low",
  "confidence": 0.0-1.0
}`
        },
        {
          role: 'user',
          content: `Analiza este comando: "${text}"`
        }
      ];

      const response = await this.generateChatResponse(messages, {
        temperature: 0.3, // M√°s determinista para an√°lisis
        max_tokens: 500
      });

      try {
        const analysis = JSON.parse(response.content);
        return analysis;
      } catch (parseError) {
        logger.warn('‚ö†Ô∏è  Failed to parse OpenAI JSON response, using fallback');
        return this.createFallbackAnalysis(text);
      }

    } catch (error) {
      logger.error('‚ùå Error analyzing intent:', error);
      return this.createFallbackAnalysis(text);
    }
  }

  /**
   * Generar contenido optimizado para blog
   */
  async generateBlogContent(prompt, type = 'improvement', config = {}) {
    try {
      const systemPrompts = {
        improvement: `Eres un especialista en optimizaci√≥n de contenido para blogs de tecnolog√≠a.
        Tu objetivo es mejorar el contenido existente para SEO, legibilidad y engagement.
        Proporciona sugerencias espec√≠ficas y actionables.`,
        
        tags: `Eres un especialista en SEO y taxonom√≠a de contenido.
        Tu trabajo es generar tags relevantes y keywords optimizadas para contenido de tecnolog√≠a.`,
        
        summary: `Eres un especialista en s√≠ntesis de contenido.
        Crea res√∫menes concisos y atractivos que capturen la esencia del contenido.`,
        
        seo: `Eres un especialista en SEO t√©cnico.
        Analiza el contenido y proporciona recomendaciones espec√≠ficas para optimizar el ranking.`
      };

      const messages = [
        {
          role: 'system',
          content: systemPrompts[type] || systemPrompts.improvement
        },
        {
          role: 'user',
          content: prompt
        }
      ];

      return await this.generateChatResponse(messages, config);

    } catch (error) {
      logger.error('‚ùå Error generating blog content:', error);
      throw error;
    }
  }

  /**
   * Formatear mensajes para OpenAI
   */
  formatMessages(messages) {
    if (typeof messages === 'string') {
      return [{ role: 'user', content: messages }];
    }

    if (Array.isArray(messages)) {
      return messages.map(msg => {
        if (typeof msg === 'string') {
          return { role: 'user', content: msg };
        }
        return msg;
      });
    }

    return [messages];
  }

  /**
   * Crear an√°lisis de respaldo cuando OpenAI falla
   */
  createFallbackAnalysis(text) {
    const textLower = text.toLowerCase();
    
    // An√°lisis b√°sico por palabras clave
    let intent = 'unknown';
    let module = 'blog';
    let action = 'analyze';
    let priority = 'medium';

    if (textLower.includes('optimiz') || textLower.includes('mejor')) {
      intent = 'optimize';
      action = 'optimize_content';
    } else if (textLower.includes('analiz') || textLower.includes('revis')) {
      intent = 'analyze';
      action = 'analyze_content';
    } else if (textLower.includes('generat') || textLower.includes('crear')) {
      intent = 'generate';
      action = 'generate_content';
    }

    if (textLower.includes('tag') || textLower.includes('keyword')) {
      action = 'generate_tags';
    } else if (textLower.includes('seo')) {
      action = 'optimize_seo';
    }

    return {
      intent,
      module,
      action,
      parameters: { text },
      priority,
      confidence: 0.6,
      fallback: true
    };
  }

  /**
   * Generar clave de cach√©
   */
  generateCacheKey(messages) {
    const content = JSON.stringify(messages);
    return Buffer.from(content).toString('base64').slice(0, 32);
  }

  /**
   * Obtener respuesta del cach√©
   */
  getFromCache(key) {
    const cached = this.cache.get(key);
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      return cached.data;
    }
    this.cache.delete(key);
    return null;
  }

  /**
   * Guardar respuesta en cach√©
   */
  saveToCache(key, data) {
    this.cache.set(key, {
      data,
      timestamp: Date.now()
    });

    // Limpiar cach√© viejo
    if (this.cache.size > 100) {
      const oldestKey = this.cache.keys().next().value;
      this.cache.delete(oldestKey);
    }
  }

  /**
   * Limpiar cach√©
   */
  clearCache() {
    this.cache.clear();
    logger.info('üßπ OpenAI cache cleared');
  }

  /**
   * Manejar estrategias de fallback cuando OpenAI no est√° disponible
   */
  async handleFallback(agentName, userMessage, taskContext, error = null) {
    logger.warn(`‚ö†Ô∏è  Using fallback strategy for ${agentName}${error ? `: ${error.message}` : ''}`);
    
    const strategy = this.fallbackStrategies.get(agentName) || this.fallbackStrategies.get('default');
    
    if (strategy) {
      return await strategy(userMessage, taskContext);
    }

    // Fallback b√°sico
    return {
      content: `Sistema funcionando en modo limitado. He recibido tu solicitud "${userMessage}" pero requiero conectividad completa para una respuesta √≥ptima. Te sugiero intentar nuevamente en unos minutos.`,
      fallback: true,
      agentName,
      timestamp: new Date()
    };
  }

  /**
   * Inicializar estrategias de fallback
   */
  initializeFallbackStrategies() {
    this.fallbackStrategies.set('BlogAgent', async (message, context) => {
      return {
        content: `üîß **An√°lisis B√°sico de Blog**
        
He recibido tu solicitud sobre contenido del blog. Sin conexi√≥n completa a IA, puedo ofrecerte:

üìä **An√°lisis disponibles:**
- Revisi√≥n de estructura b√°sica
- Validaci√≥n de elementos SEO fundamentales
- Sugerencias generales de optimizaci√≥n

üí° **Recomendaciones b√°sicas:**
- Verificar t√≠tulo y meta descripci√≥n
- Revisar densidad de palabras clave
- Comprobar estructura de encabezados

Para an√°lisis completo con IA, por favor intenta nuevamente cuando la conectividad est√© restaurada.`,
        fallback: true,
        agentName: 'BlogAgent',
        basicAnalysis: true
      };
    });

    this.fallbackStrategies.set('default', async (message, context) => {
      return {
        content: `Sistema operando en modo b√°sico. Tu consulta "${message}" ha sido registrada. Las funcionalidades completas de IA estar√°n disponibles una vez restaurada la conectividad.`,
        fallback: true,
        timestamp: new Date()
      };
    });
  }

  /**
   * Formatear contexto adicional para mensajes
   */
  formatAdditionalContext(additionalContext) {
    let formatted = '';
    
    if (additionalContext.recentBlogPosts) {
      formatted += 'POSTS RECIENTES:\n';
      additionalContext.recentBlogPosts.forEach(post => {
        formatted += `- "${post.title}" (${post.views || 0} vistas, ${post.category?.name || 'Sin categor√≠a'})\n`;
      });
      formatted += '\n';
    }

    if (additionalContext.userStats) {
      formatted += `ESTAD√çSTICAS DEL USUARIO:\n`;
      formatted += `- Miembro desde: ${additionalContext.userStats.memberSince}\n`;
      if (additionalContext.userStats.blogActivity) {
        formatted += `- Actividad en blog: ${JSON.stringify(additionalContext.userStats.blogActivity)}\n`;
      }
      formatted += '\n';
    }

    return formatted.trim();
  }

  /**
   * Estimaci√≥n inteligente de tokens
   */
  estimateTokenCount(messages) {
    let totalTokens = 0;
    
    messages.forEach(message => {
      // Estimaci√≥n m√°s precisa: ~4 chars por token en espa√±ol
      totalTokens += Math.ceil(message.content.length / 4);
      // Overhead por estructura del mensaje
      totalTokens += 4;
    });
    
    return totalTokens;
  }

  /**
   * Obtener l√≠mite de tokens para modelo
   */
  getTokenLimit(model) {
    return this.tokenLimits[model] || 8192;
  }

  /**
   * Optimizar mensajes para l√≠mite de tokens
   */
  async optimizeMessagesForTokens(messages, model) {
    const limit = this.getTokenLimit(model) * 0.8; // 80% del l√≠mite
    let currentTokens = this.estimateTokenCount(messages);
    
    if (currentTokens <= limit) {
      return messages;
    }

    logger.info(`üîß Optimizing messages: ${currentTokens} -> target: ${limit} tokens`);
    
    const optimized = [...messages];
    const systemMessage = optimized[0]; // Preservar mensaje del sistema
    const userMessage = optimized[optimized.length - 1]; // Preservar mensaje actual del usuario
    
    // Reducir mensajes del historial
    let historyMessages = optimized.slice(1, -1);
    
    while (currentTokens > limit && historyMessages.length > 1) {
      // Remover el mensaje menos importante del medio
      const middleIndex = Math.floor(historyMessages.length / 2);
      historyMessages.splice(middleIndex, 1);
      
      const newMessages = [systemMessage, ...historyMessages, userMessage];
      currentTokens = this.estimateTokenCount(newMessages);
    }
    
    // Si a√∫n es muy largo, resumir el sistema prompt
    if (currentTokens > limit) {
      systemMessage.content = this.summarizeSystemPrompt(systemMessage.content, limit * 0.3);
    }
    
    const final = [systemMessage, ...historyMessages, userMessage];
    logger.success(`‚úÖ Optimized to ${this.estimateTokenCount(final)} tokens`);
    
    return final;
  }

  /**
   * Resumir prompt del sistema
   */
  summarizeSystemPrompt(prompt, maxTokens) {
    const targetChars = maxTokens * 4; // ~4 chars por token
    
    if (prompt.length <= targetChars) {
      return prompt;
    }

    // Mantener secciones cr√≠ticas
    const criticalSections = [
      'INSTRUCCIONES:',
      'TU ESPECIALIZACI√ìN:',
      'TAREA ACTUAL:'
    ];

    let summary = '';
    const sections = prompt.split('\n\n');
    
    // Agregar secciones cr√≠ticas completas
    sections.forEach(section => {
      const isCritical = criticalSections.some(critical => section.includes(critical));
      if (isCritical && summary.length + section.length < targetChars * 0.8) {
        summary += section + '\n\n';
      }
    });

    // Agregar resumen del resto si hay espacio
    const remaining = targetChars - summary.length;
    if (remaining > 100) {
      const otherSections = sections.filter(section => 
        !criticalSections.some(critical => section.includes(critical))
      );
      
      const briefSummary = otherSections
        .join(' ')
        .substring(0, remaining - 50)
        .replace(/\s+/g, ' ')
        .trim() + '...';
        
      summary += briefSummary;
    }

    return summary;
  }

  /**
   * Cach√© inteligente con prioridad
   */
  generateSmartCacheKey(messages, agentName) {
    const messageHash = this.generateCacheKey(messages);
    return `${agentName}_${messageHash}`;
  }

  getFromSmartCache(key) {
    const cached = this.cache.get(key);
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      // Actualizar prioridad
      this.cachePriority.set(key, Date.now());
      return cached.data;
    }
    
    this.cache.delete(key);
    this.cachePriority.delete(key);
    return null;
  }

  saveToSmartCache(key, data, agentProfile) {
    // Determinar TTL basado en tipo de contenido
    let ttl = this.cacheTimeout;
    
    if (agentProfile?.technicalConfig?.cacheStrategy === 'persistent') {
      ttl = 60 * 60 * 1000; // 1 hora
    } else if (agentProfile?.technicalConfig?.cacheStrategy === 'basic') {
      ttl = 5 * 60 * 1000; // 5 minutos
    }

    this.cache.set(key, {
      data,
      timestamp: Date.now(),
      ttl
    });
    
    this.cachePriority.set(key, Date.now());

    // Limpiar cache si es muy grande
    if (this.cache.size > 200) {
      this.cleanupSmartCache();
    }
  }

  cleanupSmartCache() {
    // Remover entradas m√°s antiguas basado en prioridad y tiempo
    const sortedEntries = Array.from(this.cachePriority.entries())
      .sort((a, b) => a[1] - b[1]) // Ordenar por timestamp (m√°s antiguo primero)
      .slice(0, 50); // Remover 50 entradas m√°s antiguas

    sortedEntries.forEach(([key]) => {
      this.cache.delete(key);
      this.cachePriority.delete(key);
    });

    logger.info(`üßπ Cleaned up cache: removed ${sortedEntries.length} old entries`);
  }

  /**
   * Actualizar contexto y m√©tricas
   */
  async updateContextAndMetrics(sessionId, agentName, userMessage, response, startTime) {
    try {
      // Actualizar contexto de conversaci√≥n
      await contextManager.addMessage(sessionId, agentName, {
        role: 'user',
        content: userMessage
      });

      await contextManager.addMessage(sessionId, agentName, {
        role: 'assistant',
        content: response.content
      });

      // Actualizar m√©tricas
      const responseTime = Date.now() - startTime;
      this.metrics.averageResponseTime = 
        (this.metrics.averageResponseTime + responseTime) / this.metrics.totalRequests;

      if (response.usage) {
        this.metrics.tokensSaved += response.usage.prompt_tokens || 0;
        
        // Calcular ahorro de costos (aproximado)
        const costSaving = (response.usage.total_tokens || 0) * 0.00003; // ~$0.03/1K tokens
        this.metrics.costOptimization += costSaving;
      }

      // Actualizar m√©tricas del agente
      await personalitySystem.updateProfileMetrics(agentName, {
        responseTime,
        tokensUsed: response.usage?.total_tokens || 0
      });

    } catch (error) {
      logger.warn('‚ö†Ô∏è  Failed to update context and metrics:', error.message);
    }
  }

  /**
   * Obtener estad√≠sticas avanzadas del servicio
   */
  getAdvancedStats() {
    return {
      // Estad√≠sticas b√°sicas
      available: this.isAvailable(),
      model: this.model,
      
      // Cache
      cacheSize: this.cache.size,
      cacheHitRate: this.metrics.totalRequests > 0 ? 
        (this.metrics.cachedResponses / this.metrics.totalRequests * 100).toFixed(2) + '%' : '0%',
      
      // Performance
      metrics: {
        ...this.metrics,
        averageResponseTime: Math.round(this.metrics.averageResponseTime),
        errorRate: (this.metrics.errorRate * 100).toFixed(2) + '%',
        costOptimization: '$' + this.metrics.costOptimization.toFixed(4)
      },
      
      // L√≠mites y configuraci√≥n
      tokenLimits: this.tokenLimits,
      cacheTimeout: this.cacheTimeout / 1000, // en segundos
      
      timestamp: new Date()
    };
  }

  /**
   * Obtener estad√≠sticas simples (retrocompatibilidad)
   */
  getStats() {
    return {
      available: this.isAvailable(),
      model: this.model,
      cacheSize: this.cache.size,
      cacheTimeout: this.cacheTimeout / 1000 // en segundos
    };
  }
  /**
   * Aplicar adaptaciones de respuesta basadas en preferencias
   */
  applyResponseAdaptations(content, userPreferences) {
    if (!userPreferences) return content;
    
    let adapted = content;
    
    // Adaptar seg√∫n el nivel de detalle preferido
    switch (userPreferences.communication?.detail_level) {
      case 'brief':
        adapted = this.makeBrief(adapted);
        break;
      case 'comprehensive':
        adapted = this.makeComprehensive(adapted);
        break;
    }
    
    // Adaptar seg√∫n estilo de respuesta
    switch (userPreferences.communication?.response_style) {
      case 'step_by_step':
        adapted = this.formatAsStepByStep(adapted);
        break;
      case 'examples_heavy':
        adapted = this.emphasizeExamples(adapted);
        break;
    }
    
    return adapted;
  }

  /**
   * Mejorar respuesta con elementos adicionales seg√∫n preferencias
   */
  enhanceResponseWithPreferences(content, userPreferences) {
    let enhanced = content;
    
    // Agregar elementos seg√∫n preferencias de tarea
    if (userPreferences?.task_preferences) {
      if (userPreferences.task_preferences.include_metrics && !enhanced.includes('üìä')) {
        enhanced += '\n\nüìä **M√âTRICAS DE √âXITO**: Se recomienda monitorear los indicadores de rendimiento despu√©s de implementar las sugerencias.';
      }
      
      if (userPreferences.task_preferences.include_next_steps && !enhanced.includes('SIGUIENTES PASOS')) {
        enhanced += '\n\nüîÑ **SIGUIENTES PASOS**: \n1. Revisar y validar las recomendaciones\n2. Priorizar implementaciones\n3. Monitorear resultados';
      }
      
      if (userPreferences.task_preferences.prioritize_quick_wins && !enhanced.includes('QUICK WINS')) {
        enhanced += '\n\n‚ö° **QUICK WINS**: Implementa primero las mejoras m√°s r√°pidas para obtener resultados inmediatos.';
      }
    }
    
    return enhanced;
  }

  /**
   * Calcular satisfacci√≥n predicha
   */
  calculatePredictedSatisfaction(content, successRate) {
    let satisfaction = successRate || 0.7;
    
    // Factores que incrementan satisfacci√≥n predicha
    if (content.includes('üìä')) satisfaction += 0.05; // M√©tricas
    if (content.includes('üîÑ')) satisfaction += 0.05; // Pasos siguientes
    if (content.includes('üí°')) satisfaction += 0.03; // Consejos
    if (content.includes('‚ö°')) satisfaction += 0.04; // Quick wins
    if (content.length > 500 && content.length < 2000) satisfaction += 0.03; // Longitud apropiada
    
    return Math.min(1.0, satisfaction);
  }

  /**
   * Contar adaptaciones aplicadas
   */
  countAppliedAdaptations(adaptations) {
    if (!adaptations) return 0;
    
    return (adaptations.communication?.length || 0) +
           (adaptations.content?.length || 0) +
           (adaptations.structure?.length || 0);
  }

  /**
   * Obtener m√°ximo de mensajes de historial seg√∫n preferencias
   */
  getMaxHistoryMessages(userPreferences) {
    const detailLevel = userPreferences?.communication?.detail_level || 'standard';
    
    switch (detailLevel) {
      case 'brief': return 4; // 2 intercambios
      case 'standard': return 8; // 4 intercambios
      case 'detailed': return 12; // 6 intercambios
      case 'comprehensive': return 16; // 8 intercambios
      default: return 8;
    }
  }

  /**
   * Resumir respuesta para usuarios que prefieren brevedad
   */
  summarizeResponse(response) {
    // Extraer puntos principales usando patrones simples
    const sentences = response.split(/[.!?]+/).filter(s => s.trim().length > 0);
    const important = sentences.filter(s => 
      s.includes('importante') || 
      s.includes('recomiendo') || 
      s.includes('debes') || 
      s.includes('clave') ||
      s.includes('principal')
    );
    
    // Mantener primeras oraciones y las importantes
    const summary = [...sentences.slice(0, 2), ...important.slice(0, 2)].join('. ') + '.';
    
    return summary.length > 300 ? summary.substring(0, 297) + '...' : summary;
  }

  /**
   * Formatear contenido para usuarios que prefieren pasos
   */
  formatAsStepByStep(content) {
    // Si ya est√° estructurado, mantenerlo
    if (content.includes('\n1.') || content.includes('**1.')) {
      return content;
    }
    
    // Intentar crear estructura de pasos
    const sections = content.split('\n\n').filter(s => s.trim().length > 0);
    if (sections.length > 1) {
      return '**AN√ÅLISIS PASO A PASO:**\n\n' + 
             sections.map((section, index) => `**${index + 1}.** ${section}`).join('\n\n');
    }
    
    return content;
  }

  /**
   * Enfatizar ejemplos en el contenido
   */
  emphasizeExamples(content) {
    // Destacar ejemplos existentes
    let enhanced = content.replace(/ejemplo:/gi, '**üí° EJEMPLO:**');
    enhanced = enhanced.replace(/por ejemplo/gi, '**por ejemplo**');
    
    // Agregar ejemplo adicional si no hay suficientes
    if ((enhanced.match(/ejemplo/gi) || []).length < 2) {
      enhanced += '\n\n**üí° EJEMPLO PR√ÅCTICO:** Esta estrategia ha demostrado resultados efectivos en proyectos similares, mejorando m√©tricas clave entre 15-25%.';
    }
    
    return enhanced;
  }

  /**
   * Hacer contenido m√°s breve
   */
  makeBrief(content) {
    // Remover secciones explicativas extensas
    const brief = content
      .replace(/En primer lugar,?/gi, 'Primero:')
      .replace(/Es importante mencionar que/gi, 'Nota:')
      .replace(/Por otro lado,?/gi, 'Tambi√©n:')
      .replace(/A continuaci√≥n,?/gi, 'Siguiente:');
    
    // Mantener solo los puntos principales
    const lines = brief.split('\n').filter(line => 
      line.trim().length > 0 && 
      (line.includes('‚Ä¢') || line.includes('-') || line.includes('**') || line.length < 150)
    );
    
    return lines.join('\n');
  }

  /**
   * Hacer contenido m√°s comprehensivo
   */
  makeComprehensive(content) {
    let comprehensive = content;
    
    // Agregar contexto adicional
    if (!comprehensive.includes('CONTEXTO:')) {
      comprehensive = '**CONTEXTO:** Esta an√°lisis considera las mejores pr√°cticas actuales de la industria.\n\n' + comprehensive;
    }
    
    // Agregar consideraciones adicionales
    if (!comprehensive.includes('CONSIDERACIONES:')) {
      comprehensive += '\n\n**CONSIDERACIONES ADICIONALES:**\n- Eval√∫a el impacto en recursos disponibles\n- Considera tiempos de implementaci√≥n realistas\n- Monitorea m√©tricas de √©xito continuamente';
    }
    
    return comprehensive;
  }

  /**
   * Crear mensajes de fallback
   */
  buildFallbackMessages(userMessage, agentProfile) {
    const messages = [
      {
        role: 'system',
        content: `Eres un asistente AI especializado. Responde de manera profesional y √∫til en espa√±ol.`
      },
      {
        role: 'user',
        content: userMessage
      }
    ];
    
    return messages;
  }

  /**
   * Procesar respuesta est√°ndar (fallback)
   */
  processStandardResponse(response, agentProfile) {
    return {
      success: true,
      content: response.choices[0]?.message?.content || 'No se pudo generar respuesta.',
      predictedSatisfaction: 0.6,
      model: response.model,
      usage: response.usage,
      metadata: {
        intelligence_applied: false,
        adaptations_count: 0,
        fallback_processing: true
      }
    };
  }

  /**
   * Formatear contexto adicional
   */
  formatAdditionalContext(context) {
    return Object.entries(context)
      .map(([key, value]) => `${key}: ${JSON.stringify(value)}`)
      .join('\n');
  }
}

// Singleton instance
const openaiService = new OpenAIService();

export default openaiService;
export { OpenAIService };