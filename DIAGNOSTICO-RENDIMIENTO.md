# üîç DIAGN√ìSTICO DE RENDIMIENTO - Web Scuti Backend

## üìã Resumen Ejecutivo

**Fecha:** 12 de Noviembre, 2025  
**Sistema:** Node.js + Express + MongoDB + Clerk  
**Problema:** El servidor se cae durante consultas prolongadas  
**Causa Principal:** M√∫ltiples cuellos de botella en gesti√≥n de conexiones, consultas DB y memoria

---

## üö® PROBLEMAS CR√çTICOS IDENTIFICADOS

### 1. ‚ö†Ô∏è **CONFIGURACI√ìN DE BASE DE DATOS - CONEXIONES**

#### Problema Detectado:
```javascript
// config/database.js - L√çNEAS 16-18
const options = {
  serverSelectionTimeoutMS: 5000,  // ‚ùå MUY CORTO
  socketTimeoutMS: 45000,           // ‚ùå INSUFICIENTE
};
```

**Impacto:**
- ‚ùå Timeouts prematuros bajo carga
- ‚ùå No hay control de pool de conexiones
- ‚ùå Conexiones no se reutilizan eficientemente
- ‚ùå Memory leaks por conexiones hu√©rfanas

**Soluci√≥n:**
```javascript
const options = {
  // Timeouts m√°s realistas
  serverSelectionTimeoutMS: 10000,      // 10s para selecci√≥n de servidor
  socketTimeoutMS: 360000,               // 6 minutos para queries largos
  connectTimeoutMS: 30000,               // 30s para conectar
  
  // Pool de conexiones optimizado
  maxPoolSize: 50,                       // Max 50 conexiones simult√°neas
  minPoolSize: 10,                       // Mantener 10 conexiones m√≠nimas
  maxIdleTimeMS: 60000,                  // Cerrar conexiones idle despu√©s de 1min
  
  // Buffering y reintentos
  bufferCommands: false,                 // Fallar r√°pido en vez de bufferear
  maxConnecting: 5,                      // Max 5 conexiones inici√°ndose a la vez
  
  // Compresi√≥n (opcional pero recomendado)
  compressors: ['zlib'],
  zlibCompressionLevel: 6,
};
```

---

### 2. üêå **CONSULTAS SIN OPTIMIZAR - M√öLTIPLES POPULATES**

#### Problema Detectado:
```javascript
// Ejemplo de blogPostController.js
const posts = await BlogPost.find(query)
  .populate('author', 'firstName lastName')      // ‚ùå Populate 1
  .populate('category', 'name slug color')       // ‚ùå Populate 2  
  .populate('tags', 'name slug color')           // ‚ùå Populate 3
  .sort(sortBy)
  .skip((page - 1) * limit)
  .limit(parseInt(limit));
```

**Impacto:**
- ‚ùå **3 consultas adicionales a MongoDB** por cada post
- ‚ùå En una lista de 20 posts = **60 consultas extras**
- ‚ùå Tiempo de respuesta multiplicado por 3-4x
- ‚ùå Consumo excesivo de memoria con objetos completos

**Soluci√≥n Inmediata:**
```javascript
// OPCI√ìN A: Usar aggregation pipeline (m√°s eficiente)
const posts = await BlogPost.aggregate([
  { $match: query },
  { $sort: { [sortBy]: -1 } },
  { $skip: (page - 1) * limit },
  { $limit: parseInt(limit) },
  {
    $lookup: {
      from: 'users',
      localField: 'author',
      foreignField: '_id',
      as: 'author',
      pipeline: [{ $project: { firstName: 1, lastName: 1 } }]
    }
  },
  {
    $lookup: {
      from: 'blogcategories',
      localField: 'category',
      foreignField: '_id',
      as: 'category',
      pipeline: [{ $project: { name: 1, slug: 1, color: 1 } }]
    }
  },
  { $unwind: { path: '$author', preserveNullAndEmptyArrays: true } },
  { $unwind: { path: '$category', preserveNullAndEmptyArrays: true } }
]);

// OPCI√ìN B: Cachear las relaciones m√°s comunes
// Implementar cache en memoria para autores, categor√≠as y tags frecuentes
```

---

### 3. üíæ **FALTA DE √çNDICES COMPUESTOS CR√çTICOS**

#### Problema Detectado:
```javascript
// models/BlogPost.js - Solo √≠ndices simples
BlogPostSchema.index({ slug: 1, isPublished: 1 });
BlogPostSchema.index({ status: 1, publishedAt: -1 });
```

**Impacto:**
- ‚ùå B√∫squedas combinadas hacen **COLLSCAN** (escaneo completo)
- ‚ùå Queries como `{isPublished: true, category: X, status: 'published'}` son lentas
- ‚ùå Bajo alta concurrencia, MongoDB se satura

**Soluci√≥n:**
```javascript
// Agregar √≠ndices compuestos estrat√©gicos
BlogPostSchema.index({ isPublished: 1, status: 1, publishedAt: -1 }); // Listados p√∫blicos
BlogPostSchema.index({ category: 1, isPublished: 1, publishedAt: -1 }); // Por categor√≠a
BlogPostSchema.index({ author: 1, status: 1, createdAt: -1 }); // Posts por autor
BlogPostSchema.index({ 'tags': 1, isPublished: 1, publishedAt: -1 }); // Por tag
BlogPostSchema.index({ isFeatured: 1, isPublished: 1, publishedAt: -1 }); // Destacados
```

---

### 4. üóÑÔ∏è **SISTEMA DE CACH√â INEFICIENTE**

#### Problema Detectado:
```javascript
// middleware/serviciosCache.js - Cache en memoria
let cachedConfig = null;
let configCacheTime = 0;
const CONFIG_CACHE_DURATION = 60000; // ‚ùå Solo 1 minuto
```

**Impacto:**
- ‚ùå Cache vol√°til (se pierde al reiniciar)
- ‚ùå No hay cache distribuido (problemas en m√∫ltiples instancias)
- ‚ùå Headers de cache HTTP deshabilitados en desarrollo
- ‚ùå Cada request reconsulta datos est√°ticos

**Soluci√≥n:**

**Fase 1: Mejorar cache actual**
```javascript
const CONFIG_CACHE_DURATION = 300000; // 5 minutos en vez de 1
```

**Fase 2: Implementar Redis (RECOMENDADO)**
```bash
npm install redis ioredis
```

```javascript
// config/redis.js
import Redis from 'ioredis';

const redis = new Redis({
  host: process.env.REDIS_HOST || 'localhost',
  port: process.env.REDIS_PORT || 6379,
  password: process.env.REDIS_PASSWORD,
  retryStrategy: (times) => Math.min(times * 50, 2000),
  maxRetriesPerRequest: 3
});

export default redis;

// middleware/redisCache.js
export const redisCacheMiddleware = (duration = 300) => {
  return async (req, res, next) => {
    const key = `cache:${req.originalUrl}`;
    
    try {
      const cached = await redis.get(key);
      if (cached) {
        return res.json(JSON.parse(cached));
      }
      
      // Override res.json para guardar en cache
      const originalJson = res.json.bind(res);
      res.json = (data) => {
        redis.setex(key, duration, JSON.stringify(data));
        return originalJson(data);
      };
      
      next();
    } catch (error) {
      next(); // Continuar si Redis falla
    }
  };
};
```

---

### 5. üö¶ **RATE LIMITING INSUFICIENTE**

#### Problema Detectado:
```javascript
// server.js - L√çNEAS 116-120
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: process.env.NODE_ENV === 'production' ? 100 : 1000, // ‚ùå 100 es MUY BAJO
  skip: () => process.env.NODE_ENV === 'development' // ‚ùå Deshabilitado en dev
});
```

**Impacto:**
- ‚ùå Usuarios leg√≠timos bloqueados (100 requests / 15min = 6.6/min)
- ‚ùå No hay rate limiting diferenciado por tipo de request
- ‚ùå Ataques DDoS simples pueden saturar el servidor

**Soluci√≥n:**
```javascript
// Rate limits diferenciados y m√°s realistas
const generalLimiter = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 500, // 500 requests / 15min = ~33/min (m√°s realista)
  standardHeaders: true,
  legacyHeaders: false,
  handler: (req, res) => {
    res.status(429).json({
      success: false,
      message: 'Demasiadas peticiones. Intenta de nuevo en 15 minutos.',
      retryAfter: 900
    });
  }
});

// Rate limit espec√≠fico para rutas p√∫blicas de lectura (m√°s permisivo)
const publicReadLimiter = rateLimit({
  windowMs: 1 * 60 * 1000,
  max: 60, // 60/min para lectura p√∫blica
  skip: (req) => req.method !== 'GET'
});

// Rate limit estricto para operaciones de escritura
const writeLimiter = rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 50, // 50 writes / 15min
  skip: (req) => req.method === 'GET'
});

// Aplicar por ruta
app.use('/api/blog', publicReadLimiter);
app.use('/api/servicios', publicReadLimiter);
app.use('/api/admin', authLimiter, writeLimiter);
```

---

### 6. üñºÔ∏è **PROCESAMIENTO DE IM√ÅGENES BLOQUEANTE**

#### Problema Detectado:
```javascript
// utils/imageProcessor.js - Sharp es s√≠ncrono en implementaci√≥n actual
const info = await sharp(filePath)
  .resize(width, height, { fit: 'cover' })
  .toFile(outputPath);
```

**Impacto:**
- ‚ùå **Bloquea el event loop** durante procesamiento intensivo
- ‚ùå Servidor no puede manejar otras requests mientras procesa im√°genes
- ‚ùå Consumo de memoria en picos (Sharp carga toda la imagen)

**Soluci√≥n:**
```javascript
// Opci√≥n A: Worker Threads (nativo Node.js)
import { Worker } from 'worker_threads';

export const processImageInBackground = (filePath, options) => {
  return new Promise((resolve, reject) => {
    const worker = new Worker('./workers/imageWorker.js', {
      workerData: { filePath, options }
    });
    
    worker.on('message', resolve);
    worker.on('error', reject);
    worker.on('exit', (code) => {
      if (code !== 0) reject(new Error(`Worker stopped with exit code ${code}`));
    });
  });
};

// Opci√≥n B: Queue con Bull (recomendado para producci√≥n)
import Bull from 'bull';

const imageQueue = new Bull('image-processing', {
  redis: { host: 'localhost', port: 6379 }
});

imageQueue.process(async (job) => {
  const { filePath, options } = job.data;
  return await sharp(filePath).resize(options.width).toFile(options.outputPath);
});

export const queueImageProcessing = (filePath, options) => {
  return imageQueue.add({ filePath, options });
};
```

---

### 7. üìä **MEMORY LEAKS POTENCIALES**

#### Problema Detectado:
```javascript
// server.js - No hay l√≠mites de memoria configurados
app.use(express.json()); // ‚ùå Sin l√≠mite de tama√±o
app.use(fileUpload({
  limits: { fileSize: 5 * 1024 * 1024 } // ‚ùå Solo limita archivo, no memoria total
}));
```

**Impacto:**
- ‚ùå Request con JSON gigante puede causar OutOfMemory
- ‚ùå M√∫ltiples uploads simult√°neos saturan RAM
- ‚ùå No hay monitoreo de uso de memoria

**Soluci√≥n:**
```javascript
// Limitar tama√±o de payload
app.use(express.json({ limit: '1mb' })); // Max 1MB por request JSON
app.use(express.urlencoded({ extended: true, limit: '1mb' }));

// Configurar limits m√°s estrictos para file upload
app.use(fileUpload({
  limits: { 
    fileSize: 5 * 1024 * 1024,  // 5MB por archivo
    files: 3                     // Max 3 archivos simult√°neos
  },
  abortOnLimit: true,
  responseOnLimit: 'El archivo excede el tama√±o m√°ximo permitido (5MB)',
  useTempFiles: true,            // Usar archivos temporales en vez de memoria
  tempFileDir: '/tmp/'
}));

// Monitoreo de memoria (agregar middleware)
app.use((req, res, next) => {
  const used = process.memoryUsage();
  if (used.heapUsed > 500 * 1024 * 1024) { // Si usa m√°s de 500MB
    console.warn('‚ö†Ô∏è High memory usage:', Math.round(used.heapUsed / 1024 / 1024) + 'MB');
  }
  next();
});
```

---

### 8. üîÑ **NO HAY ESTRATEGIA DE GRACEFUL SHUTDOWN**

#### Problema Detectado:
```javascript
// server.js - L√çNEAS 364-367
process.on('SIGTERM', () => {
  server.close(() => {
    console.log('HTTP server closed');
  }); // ‚ùå No cierra conexiones de DB, Redis, etc.
});
```

**Impacto:**
- ‚ùå Conexiones activas a MongoDB quedan abiertas
- ‚ùå Requests en progreso se cortan abruptamente
- ‚ùå Datos en cache en memoria se pierden

**Soluci√≥n:**
```javascript
// Graceful shutdown completo
const gracefulShutdown = async (signal) => {
  console.log(`\n${signal} received: closing gracefully`);
  
  // 1. Dejar de aceptar nuevas conexiones
  server.close(() => {
    console.log('‚úì HTTP server closed');
  });
  
  // 2. Esperar requests en progreso (max 30s)
  setTimeout(() => {
    console.error('‚ö†Ô∏è Forcing shutdown after timeout');
    process.exit(1);
  }, 30000);
  
  try {
    // 3. Cerrar conexi√≥n a MongoDB
    await mongoose.connection.close(false);
    console.log('‚úì MongoDB connection closed');
    
    // 4. Cerrar conexi√≥n a Redis (si existe)
    if (redis) {
      await redis.quit();
      console.log('‚úì Redis connection closed');
    }
    
    // 5. Salir limpiamente
    console.log('‚úì Graceful shutdown completed');
    process.exit(0);
  } catch (error) {
    console.error('‚ùå Error during shutdown:', error);
    process.exit(1);
  }
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));
```

---

## üéØ PLAN DE ACCI√ìN PRIORIZADO

### üî¥ **CR√çTICO - Implementar AHORA (1-2 d√≠as)**

1. **Arreglar configuraci√≥n de MongoDB**
   - Agregar pool de conexiones (maxPoolSize, minPoolSize)
   - Aumentar timeouts realistas
   - Archivo: `config/database.js`

2. **Optimizar consultas m√°s usadas**
   - Convertir populates a aggregation en endpoints p√∫blicos
   - Archivos: `controllers/blogPostController.js`, `controllers/servicioController.js`

3. **Agregar √≠ndices compuestos**
   - Ejecutar script de migraci√≥n de √≠ndices
   - Archivo: `models/BlogPost.js`, `models/Servicio.js`

4. **Implementar graceful shutdown**
   - Cerrar conexiones ordenadamente
   - Archivo: `server.js`

### üü° **IMPORTANTE - Implementar en 1 semana**

5. **Implementar Redis para cache**
   - Instalar Redis
   - Migrar cache en memoria a Redis
   - Configurar invalidaci√≥n inteligente

6. **Optimizar rate limiting**
   - Ajustar l√≠mites m√°s realistas
   - Diferenciar por tipo de operaci√≥n

7. **Procesar im√°genes en background**
   - Implementar worker threads o queue
   - Evitar bloqueo del event loop

### üü¢ **MEJORAS - Implementar en 2-4 semanas**

8. **Monitoreo y m√©tricas**
   - Implementar APM (Application Performance Monitoring)
   - Herramientas sugeridas: PM2, New Relic, Datadog

9. **Load testing**
   - Usar Artillery o k6 para simular carga
   - Identificar l√≠mites reales del sistema

10. **Documentaci√≥n de arquitectura**
    - Documentar flujos cr√≠ticos
    - Diagramas de arquitectura

---

## üìà M√âTRICAS ESPERADAS POST-IMPLEMENTACI√ìN

| M√©trica | Antes | Despu√©s (Estimado) |
|---------|-------|-------------------|
| Tiempo de respuesta (listado posts) | 800-1200ms | 150-300ms |
| Requests por segundo | 10-20 | 100-200 |
| Uso de memoria | 300-500MB | 150-250MB |
| Conexiones DB simult√°neas | 5-10 | 30-40 (controladas) |
| Tasa de errores bajo carga | 15-25% | <2% |

---

## üõ†Ô∏è SCRIPTS DE MIGRACI√ìN NECESARIOS

### Script 1: Crear √≠ndices compuestos
```javascript
// scripts/addIndexes.js
import mongoose from 'mongoose';
import BlogPost from '../models/BlogPost.js';
import Servicio from '../models/Servicio.js';

async function addIndexes() {
  await mongoose.connect(process.env.MONGODB_URI);
  
  console.log('Creating BlogPost indexes...');
  await BlogPost.collection.createIndex({ isPublished: 1, status: 1, publishedAt: -1 });
  await BlogPost.collection.createIndex({ category: 1, isPublished: 1, publishedAt: -1 });
  await BlogPost.collection.createIndex({ author: 1, status: 1, createdAt: -1 });
  
  console.log('Creating Servicio indexes...');
  await Servicio.collection.createIndex({ activo: 1, destacado: 1, orden: 1 });
  await Servicio.collection.createIndex({ categoria: 1, activo: 1 });
  
  console.log('‚úì Indexes created successfully');
  process.exit(0);
}

addIndexes().catch(console.error);
```

### Script 2: Analizar queries lentas
```javascript
// scripts/analyzeSlowQueries.js
import mongoose from 'mongoose';

async function analyzeSlowQueries() {
  await mongoose.connect(process.env.MONGODB_URI);
  
  const db = mongoose.connection.db;
  const profiling = await db.command({ profile: 2, slowms: 100 });
  
  console.log('Slow queries enabled. Check system.profile collection.');
  
  setTimeout(async () => {
    const slowQueries = await db.collection('system.profile')
      .find({ millis: { $gte: 100 } })
      .sort({ ts: -1 })
      .limit(20)
      .toArray();
    
    console.log('\n=== TOP 20 SLOW QUERIES ===\n');
    slowQueries.forEach((q, i) => {
      console.log(`${i+1}. ${q.command?.find || q.command?.aggregate} - ${q.millis}ms`);
      console.log(`   Namespace: ${q.ns}`);
      console.log(`   Plan: ${JSON.stringify(q.planSummary)}\n`);
    });
    
    process.exit(0);
  }, 60000); // Analizar durante 1 minuto
}

analyzeSlowQueries().catch(console.error);
```

---

## üí° RECOMENDACIONES ADICIONALES

### Infraestructura
- **Usar PM2** para gesti√≥n de procesos en producci√≥n
- **Implementar load balancer** si el tr√°fico supera 1000 req/min
- **MongoDB Atlas** con sharding si la DB supera 50GB

### Monitoreo
- **Implementar health checks** (`/health`, `/ready`)
- **Logs centralizados** con Winston + Elasticsearch/Loki
- **Alertas autom√°ticas** cuando memoria > 70% o CPU > 80%

### Seguridad
- **Helmet.js** para headers de seguridad
- **Rate limiting por IP + por usuario**
- **Validaci√≥n estricta de inputs** con Joi/Yup

---

## üìû SIGUIENTE PASO

**¬øPor d√≥nde empezar?**

1. Implementa los cambios de `config/database.js` (5 minutos)
2. Agrega los √≠ndices compuestos (10 minutos)
3. Implementa graceful shutdown (15 minutos)
4. Prueba con load testing b√°sico

**Comando para probar:**
```bash
# Instalar Artillery
npm install -g artillery

# Crear test b√°sico
cat > load-test.yml << EOF
config:
  target: 'http://localhost:5000'
  phases:
    - duration: 60
      arrivalRate: 10
scenarios:
  - flow:
    - get:
        url: "/api/blog/posts"
    - get:
        url: "/api/servicios"
EOF

# Ejecutar test
artillery run load-test.yml
```

---

**Creado por:** Diagn√≥stico Automatizado  
**Para:** Web Scuti Backend Team  
**√öltima actualizaci√≥n:** 12 Nov 2025
